{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# install dependencies\nInstall necessary Python libraries for data processing and deep learning."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os  # Provides functions for interacting with the operating system.\n",
    "import cv2  # OpenCV library for computer vision tasks.\n",
    "import tensorflow as tf  # TensorFlow library for deep learning tasks.\n",
    "import numpy as np  # NumPy library for numerical operations.\n",
    "from typing import List  # Import List for type hinting.\n",
    "from matplotlib import pyplot as plt  # Matplotlib's pyplot for plotting graphs.\n",
    "import imageio  # Imageio for reading and writing image data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tf.config.list_physical_devices('GPU')  # Lists available GPU devices for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)  # Enable memory growth for the GPU.\n",
    "except:\n",
    "    pass  # If there is no GPU, pass."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading Functions\nDefine functions to load and preprocess video data for the model."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import gdown  # Google Drive download utility."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(path: str): \n",
    "    path = bytes.decode(path.numpy())  # Decodes the file path from bytes to string.\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0]  # Extracts the file name from the path.\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')  # Constructs the full path to the video file.\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')  # Constructs the path to the alignment file.\n",
    "    frames = load_video(video_path)  # Calls the function to load video frames.\n",
    "    alignments = load_alignments(alignment_path)  # Calls the function to load text alignments.\n",
    "    return frames, alignments  # Returns the loaded video frames and text alignments."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "    cap = cv2.VideoCapture(path)  # Opens the video file.\n",
    "    frames = []  # Initializes a list to store video frames.\n",
    "    # Loops over all frames in the video.\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()  # Reads the next frame from the video.\n",
    "        frame = tf.image.rgb_to_grayscale(frame)  # Converts the frame to grayscale.\n",
    "        frames.append(frame[190:236,80:220,:])  # Crops and appends the frame to the list.\n",
    "    cap.release()  # Releases the video file.\n",
    "    mean = tf.math.reduce_mean(frames)  # Calculates the mean of the frames.\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))  # Calculates the standard deviation of the frames.\n",
    "    return tf.cast((frames - mean), tf.float32) / std  # Normalizes the frames and returns them."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]  # Defines the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")  # Maps characters to integers.\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)  # Maps integers back to characters."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f:  # Opens the alignment file.\n",
    "        lines = f.readlines()  # Reads all lines from the file.\n",
    "    tokens = []  # Initializes a list to store tokens.\n",
    "    for line in lines:  # Loops over each line in the file.\n",
    "        line = line.split()  # Splits the line into parts.\n",
    "        if line[2] != 'sil':  # If the token is not silence.\n",
    "            tokens = [*tokens,' ',line[2]]  # Adds the token to the list.\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]  # Converts tokens to numbers and returns them."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(path: str): \n",
    "    # This is a duplicated function with the same name as above. Typically, you would only need one definition. Make sure to use the correct one."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))  # Wraps the Python function `load_data` to use it in TensorFlow operations.\n",
    "    return result  # Returns the result of the wrapped function."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_path = '.\\\\data\\\\data\\\\s1\\\\bbal6n.mpg'  # Defines a test path for a video file."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pipeline\nSet up the data pipeline for feeding data into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = tf.data.Dataset.list_files('./data/data/s1/*.mpg')  # Creates a dataset of video file paths.\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)  # Shuffles the dataset.\n",
    "data = data.map(mappable_function)  # Applies the function to each element in the dataset.\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))  # Groups dataset elements into batches and pads them.\n",
    "data = data.prefetch(tf.data.AUTOTUNE)  # Prefetches dataset elements for faster access.\n",
    "train = data.take(450)  # Takes the first 450 elements for training.\n",
    "test = data.skip(450)  # Skips the first 450 elements, using the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sample = data.as_numpy_iterator()  # Creates an iterator to go through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "val = sample.next(); val[0]  # Retrieves the next batch from the iterator."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "imageio.mimsave('./animation.gif', val[0][0], fps=10)  # Saves the first video in the batch as a GIF."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Design Deep Neural Network\nDesign the architecture of the deep neural network for processing the data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler  # Imports necessary modules for building and training the model."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential()  # Creates a new Sequential model.\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))  # Adds a 3D convolutional layer.\n",
    "model.add(Activation('relu'))  # Adds a ReLU activation layer.\n",
    "model.add(MaxPool3D((1,2,2)))  # Adds a 3D max pooling layer.\n",
    "# Continues adding layers to build the complete model structure."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()  # Prints a summary of the model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "yhat = model.predict(val[0])  # Makes a prediction using the model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the Neural Network\nTrain the model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr  # Returns the learning rate unchanged for the first 30 epochs.\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)  # Reduces the learning rate for epochs after the 30th."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Defines a custom function for the CTC loss calculation.\n",
    "    # This function calculates the CTC loss for each batch."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    # Defines a custom callback to display examples of model predictions during training."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)  # Compiles the model with the Adam optimizer and custom CTC loss."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)  # Sets up a checkpointing callback."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)  # Sets up a learning rate scheduling callback."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "example_callback = ProduceExample(test)  # Sets up an example producing callback using the test data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(train, validation_data=test, epochs=3, callbacks=[checkpoint_callback, schedule_callback, example_callback])\n  # Trains the model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Predictions\nUse the trained model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "output = 'checkpoints.zip'\n",
    "gdown.download(url, output, quiet=False)  # Downloads a file from Google Drive.\n",
    "gdown.extractall('checkpoints.zip', 'models')  # Extracts the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.load_weights('models/checkpoint')  # Loads the model weights."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = test.as_numpy_iterator()  # Creates an iterator for the test data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sample = test_data.next()  # Gets a sample from the test data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "yhat = model.predict(sample[0])  # Predicts using the model on the test sample."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Decodes the predictions to text and compares them with the real text labels."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Continues the process of decoding and comparing predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Demo!\nDemonstrates how to use the model for prediction on new video data."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bbbs7a.mpg'))  # Loads a new sample for the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Displays the real text from the demonstration sample."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))  # Predicts on the new sample."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()  # Decodes the prediction."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Displays the predictions for the demonstration sample."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "version": "3.10.8"
  }
 }
}
